# geoffreyengram â€” Cognitive Memory for AI Characters

## Immediate Task: Create the Repo + Initial Docs

1. Create new repo at `~/Projects/2026/geoffreyengram`
2. Initialize Go module: `github.com/goblincore/geoffreyengram`
3. Write README.md summarizing this architecture document
4. Copy cogmem package from `club-mutant/services/dream-npc-go/npc/cogmem/` as starting point
5. git init + initial commit

The Club Mutant cogmem will eventually be replaced by importing this package, but existing implementation stays for now.

---

# Architecture Document

## What Is This

A standalone cognitive memory engine for AI characters â€” NPCs, companions, chatbots, agents. Instead of flat key-value memory or raw conversation logs, cogmem organizes memories into **cognitive sectors** (episodic, semantic, procedural, emotional, reflective) with natural decay, associative recall, and reflective synthesis.

Born from CaviraOSS's OpenMemory model (which targets coding assistants), reapplied to where it arguably matters more: characters that remember you, notice patterns, and think between conversations.

## Why This Matters

Every AI companion app has terrible memory:

| Platform | Memory | The problem |
|----------|--------|-------------|
| Replika | Context window only | Forgets things from the same day |
| Character.ai | 400-char manual tags | Doesn't transfer across chats |
| Kindroid | User-curated "Lorebooks" | Works, but users do all the work |
| Nomi | Good in-session | Weak across sessions |

The universal complaint: *"Every conversation feels like they're meeting me for the first time."*

Existing memory infra (Mem0, Zep) is generic â€” built for coding assistants and chatbots. Nobody is building cognitive memory **specifically for character AI**.

## What Makes cogmem Different

| Capability | Flat memory / RAG | cogmem |
|-----------|-------------------|--------|
| Organization | One bucket | 5 cognitive sectors |
| Importance | Everything equal | Salience scoring (0â€“1) |
| Forgetting | Manual delete or forever | Natural exponential decay |
| Associations | None | Waypoint entity graph |
| Retrieval | Keyword / vector match | Composite: similarity Ã— salience Ã— recency Ã— associations Ã— sector weight |
| Between conversations | Nothing | Reflective synthesis â€” character notices patterns, forms opinions |
| Personality | N/A | Per-character sector weights (a warm bartender values emotional memories; a scholar values semantic) |

## The Cognitive Model

### Five Sectors

| Sector | What it stores | Decay rate | Example |
|--------|---------------|------------|---------|
| **Episodic** | Events, experiences | Medium (Î»=0.02) | "Player visited Tokyo last month" |
| **Semantic** | Facts, knowledge | Very slow (Î»=0.005) | "Player's name is Alex, likes jazz" |
| **Procedural** | Skills, how-tos, routines | Slow (Î»=0.008) | "Player always orders a Nebula Fizz" |
| **Emotional** | Sentiments, feelings | Medium-fast (Î»=0.03) | "Player seemed sad last conversation" |
| **Reflective** | Meta-observations, patterns | Slow (Î»=0.01) | "Player always mentions music when stressed" |

### Composite Scoring

```
score = (0.6 Ã— similarity + 0.2 Ã— salience + 0.1 Ã— recency + 0.1 Ã— linkWeight) Ã— sectorWeight
```

- **Similarity** (60%) â€” cosine similarity between query and memory embeddings
- **Salience** (20%) â€” how important this memory is (0â€“1, boosted by access, decays over time)
- **Recency** (10%) â€” exponential decay from last access
- **Link weight** (10%) â€” bonus from waypoint graph connections
- **Sector weight** â€” per-character multiplier (bartender: episodic 1.5Ã—, emotional 1.5Ã—)

### Waypoint Graph

Memories are linked through shared entities (people, places, topics). When you recall "Japan," the graph also surfaces memories about "jazz" (because you mentioned jazz bars in Tokyo), "their dog" (because they mentioned missing the dog while traveling), etc. One-hop associative expansion.

### Natural Decay

Important memories persist. Trivial ones fade. High-salience memories decay slowly; low-salience memories expire naturally. Background worker runs every 12 hours. No manual cleanup needed.

### High-Salience Guarantee

Explicit user requests ("Always greet me with Howdy Cowboy") get stored with high salience. Even when the search query has low cosine similarity (a casual "hi"), these memories are guaranteed to surface â€” up to 2 high-salience memories injected per search regardless of similarity score.

## Reflective Synthesis (the differentiator)

The difference between "NPC with a database" and "character that thinks":

```
Player leaves the bar
        â†“
    [Time passes]
        â†“
Reflective worker fires for this player
        â†“
Loads recent episodic memories â†’ finds patterns
        â†“
LLM generates a "thought" the character would have
  â†’ "They always mention music when they're sad"
  â†’ "They've been talking about Japan a lot â€” I found a poet they'd love"
        â†“
Stored as SectorReflective (high salience)
        â†“
Player returns â†’ reflection surfaces in greeting
        â†“
"hey... I was thinking about what you said about Japan.
 do you know Kobayashi Issa? his haiku remind me of home..."
```

This isn't reactive recall â€” it's the character forming opinions and making connections *between* conversations.

## Architecture

### Form Factor: Go Library + MCP Server

```bash
# Embed in your Go game server (what Club Mutant does)
go get github.com/goblincore/cogmem

# Run as standalone MCP server for any app
go install github.com/goblincore/cogmem/cmd/cogmem-mcp

# Debug/inspect memories
go install github.com/goblincore/cogmem/cmd/cogmem-inspect
```

### Why Go (not Rust)

| Factor | Go | Rust |
|--------|----|----|
| Already written | âœ… ~1300 lines, production-tested | Would be full rewrite |
| Single binary | âœ… | âœ… |
| Background workers | âœ… Goroutines (natural fit) | Tokio (fine, more complex) |
| SQLite | modernc.org (pure Go, no CGO) | rusqlite (mature) |
| MCP SDK | mcp-go (good) | mcp-rust (good) |
| Game engine embed | âŒ Not practical | âœ… Via C FFI / Wasm |

**Why embedding in a game engine doesn't matter:** The LLM call (100-2000ms) dwarfs any IPC overhead (1ms localhost). The character's brain needs to be a sidecar service anyway â€” it persists across sessions, survives crashes, and serves multiple game instances. Rust/Wasm only matters for offline browser games, which is a niche that can be addressed later if demand appears.

### MCP Server Tools

```
cogmem-mcp
â”‚
â”œâ”€â”€ remember    â€” Store a memory
â”‚   params: content, user_id, sector_hint?, entities?, session_id?
â”‚
â”œâ”€â”€ recall      â€” Search memories
â”‚   params: query, user_id, limit?, time_after?, time_before?, sectors?
â”‚
â”œâ”€â”€ reflect     â€” Trigger reflective synthesis
â”‚   params: user_id
â”‚   returns: new reflective observations generated
â”‚
â”œâ”€â”€ forget      â€” Remove specific memories
â”‚   params: memory_id | user_id + query
â”‚
â””â”€â”€ inspect     â€” Debug/browse (admin)
    params: user_id, sector?, limit?
```

### Two Integration Patterns

**Pattern A â€” Server-driven (simple, predictable, cheaper)**
```
Player says "hi"
  â†’ Your server calls recall(user_id) â†’ gets memories
  â†’ Your server builds LLM prompt with memories
  â†’ LLM generates response
  â†’ Your server calls remember(response)
```
You control when memory is read/written. Deterministic pipeline. This is what Club Mutant does today.

**Pattern B â€” Agent-driven (autonomous, emergent, higher cost)**
```
Player says "hi"
  â†’ LLM agent has recall/remember as tools
  â†’ LLM decides: "Let me check if I know them" â†’ calls recall
  â†’ LLM decides: "This is worth remembering" â†’ calls remember
  â†’ LLM decides: "This small talk isn't worth storing" â†’ skips remember
```
The character has **agency over its own memory** â€” it decides what to remember, what to search for, what to forget. More LLM calls, but more emergent behavior. Same MCP tools support both patterns.

### Pluggable Providers

```go
// Embedding â€” bring your own vector provider
type EmbeddingProvider interface {
    Embed(text string, taskType string) ([]float32, error)
    Dimension() int
}
// Built-in: Gemini, OpenAI, Ollama (local, no API key)

// Classification â€” sector routing
type SectorClassifier interface {
    Classify(content string) Sector
}
// Built-in: heuristic keywords + LLM fallback

// Entity extraction â€” domain-specific
type EntityExtractor interface {
    Extract(content string) []Entity
}
// Built-in: brackets, quotes, capitalized phrases
// Users add: MusicExtractor, GameItemExtractor, etc.
```

## Project Structure

```
cogmem/
â”œâ”€â”€ cogmem.go          # Core engine (Init, Search, Add, Reflect, Close)
â”œâ”€â”€ config.go          # Configurable scoring weights, decay rates, caps
â”œâ”€â”€ types.go           # Sector, Memory, Entity, SearchResult
â”œâ”€â”€ store.go           # SQLite persistence + migrations
â”œâ”€â”€ scoring.go         # Composite scoring + cosine similarity
â”œâ”€â”€ decay.go           # Decay worker + exponential model
â”œâ”€â”€ waypoints.go       # Entity graph (pluggable extractors)
â”œâ”€â”€ classify.go        # Sector classification (heuristic + LLM fallback)
â”œâ”€â”€ reflect.go         # Reflective synthesis engine
â”œâ”€â”€ temporal.go        # Time windows, conversation threading
â”‚
â”œâ”€â”€ embed/             # Embedding providers
â”‚   â”œâ”€â”€ provider.go    # Interface
â”‚   â”œâ”€â”€ gemini.go
â”‚   â”œâ”€â”€ openai.go
â”‚   â””â”€â”€ ollama.go
â”‚
â”œâ”€â”€ extract/           # Entity extractors
â”‚   â”œâ”€â”€ extractor.go   # Interface
â”‚   â””â”€â”€ default.go     # Brackets, quotes, capitalized phrases
â”‚
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ cogmem-mcp/    # MCP server binary
â”‚   â””â”€â”€ cogmem-inspect/# CLI inspector
â”‚
â””â”€â”€ examples/
    â”œâ”€â”€ npc-bartender/ # Club Mutant use case
    â””â”€â”€ companion/     # Simple AI companion example
```

## What Exists vs. What Needs Building

### Already built (~80% general-purpose):
- âœ… Sector model, types, scoring formula
- âœ… SQLite persistence + vector storage
- âœ… Exponential decay + background worker
- âœ… Waypoint entity graph + one-hop expansion
- âœ… Gemini embeddings + sector classification
- âœ… High-salience guarantee
- âœ… cogmem-inspect CLI tool

### Needs extraction/genericizing:
- âš ï¸ Hardcoded Gemini model â†’ EmbeddingProvider interface
- âš ï¸ Hardcoded music artist list â†’ pluggable EntityExtractor
- âš ï¸ Summary format assumes "user â†’ npc" â†’ generic formatter
- âš ï¸ Scoring weights hardcoded â†’ configurable via Config

### Needs building (new):
- ğŸ”¨ MCP server (cmd/cogmem-mcp)
- ğŸ”¨ Reflective synthesis engine (reflect.go)
- ğŸ”¨ Conversation threading (session_id, parent_id)
- ğŸ”¨ Time-window queries (SearchTimeWindow)
- ğŸ”¨ OpenAI + Ollama embedding providers
- ğŸ”¨ Configurable scoring weights

## Implementation Phases

### Phase 1: Extract & Genericize (2-3 days)
- New repo, copy cogmem package
- Add EmbeddingProvider interface (keep Gemini default, add Ollama)
- Add EntityExtractor interface (move music artists to example)
- Make scoring weights + decay rates configurable
- Generic summary builder
- Tests against existing SQLite test data

### Phase 2: MCP Server (2-3 days)
- cmd/cogmem-mcp using mcp-go SDK
- Tools: remember, recall, forget, inspect
- Config via env vars or YAML
- Test: connect from Claude Desktop, verify remember/recall cycle

### Phase 3: Temporal Enrichment (2-3 days)
- session_id + parent_id columns in memories table
- SearchTimeWindow() method
- Conversation threading support
- "What happened last time?" queries

### Phase 4: Reflective Synthesis (3-4 days)
- Reflect() method â€” periodic pattern detection across recent memories
- LLM-powered reflection ("Given these memories, what patterns emerge?")
- Store reflective observations as high-salience memories
- Configurable reflection interval + triggers

### Phase 5: Polish & Examples (2-3 days)
- Club Mutant example (extract current integration)
- Simple companion chatbot example
- README, docs, API reference
- Benchmark: 1000 memories, search latency < 50ms

## Who Uses This

| Audience | How they use it | Value |
|----------|----------------|-------|
| **Game devs** | Library embed or MCP sidecar | NPCs that remember players across sessions |
| **AI companion builders** | MCP server as memory backend | Solves the "forgetting" problem (Replika/Character.ai gap) |
| **SillyTavern community** | MCP plugin | Drop-in long-term memory for custom characters |
| **Agent builders** | Library or MCP | Agents with cognitive structure, not just flat memory |

## Name Candidates
- **cogmem** â€” straightforward, technical
- **engram** â€” neuroscience term for a memory trace
- **myco** â€” mycorrhizal network (underground fungal memory network, fits the alien flower origin story)
